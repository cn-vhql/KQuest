"""
æ··åˆæ¨ç†å¼•æ“ - ç»“åˆLLMè¯­ä¹‰ç†è§£å’Œå›¾ç®—æ³•ç»“æ„æ¨ç†
"""

import logging
import json
from typing import Any, Dict, List, Optional, Tuple
from dataclasses import dataclass

from openai import AsyncOpenAI

from .models import KnowledgeGraph, KnowledgeTriple as Triple
from .config import get_config
from .graph_reasoner import GraphReasoner, ReasoningResult, PathResult


@dataclass
class HybridReasoningResult:
    """æ··åˆæ¨ç†ç»“æœ"""
    answer: str
    confidence: float
    reasoning_method: str
    graph_paths: List[str]
    semantic_insights: List[str]
    supporting_triples: List[Triple]
    llm_enhancement: Optional[str]
    processing_time: float


@dataclass
class QueryAnalysis:
    """æŸ¥è¯¢åˆ†æç»“æœ"""
    entities: List[str]
    intent_type: str  # "factual", "causal", "comparative", "procedural"
    complexity: str   # "simple", "medium", "complex"
    requires_llm: bool


class HybridReasoner:
    """æ··åˆæ¨ç†å¼•æ“"""

    def __init__(self, knowledge_graph: Optional[KnowledgeGraph] = None):
        self.config = get_config()
        self.logger = logging.getLogger(__name__)

        # åˆå§‹åŒ–ä¸¤ä¸ªæ¨ç†å¼•æ“
        self.graph_reasoner = GraphReasoner(knowledge_graph)
        self.llm_client = AsyncOpenAI(**self.config.get_openai_client_config())

        # æ¨ç†ç­–ç•¥é…ç½®
        self.strategies = {
            "simple_factual": {"use_graph": True, "use_llm": False, "weight": 0.8},
            "complex_reasoning": {"use_graph": True, "use_llm": True, "weight": 0.6},
            "semantic_query": {"use_graph": False, "use_llm": True, "weight": 0.9},
            "path_finding": {"use_graph": True, "use_llm": True, "weight": 0.7},
            "comparative": {"use_graph": True, "use_llm": True, "weight": 0.5}
        }

    def update_knowledge_graph(self, knowledge_graph: KnowledgeGraph) -> None:
        """æ›´æ–°çŸ¥è¯†å›¾è°±"""
        self.graph_reasoner.update_knowledge_graph(knowledge_graph)

    async def _analyze_query(self, question: str) -> QueryAnalysis:
        """åˆ†ææŸ¥è¯¢ç±»å‹å’Œå¤æ‚åº¦"""
        try:
            # ä½¿ç”¨LLMåˆ†ææŸ¥è¯¢æ„å›¾
            analysis_prompt = f"""
è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·æŸ¥è¯¢çš„ç±»å‹å’Œå¤æ‚åº¦ï¼š

æŸ¥è¯¢ï¼š"{question}"

è¯·è¿”å›JSONæ ¼å¼ï¼š
{{
    "entities": ["æå–å‡ºçš„å®ä½“1", "å®ä½“2"],
    "intent_type": "factual|causal|comparative|procedural",
    "complexity": "simple|medium|complex",
    "requires_llm": true/false,
    "reasoning": "åˆ†æåŸå› "
}}
"""

            response = await self.llm_client.chat.completions.create(
                model=self.config.openai.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæŸ¥è¯¢åˆ†æä¸“å®¶ï¼Œæ“…é•¿ç†è§£ç”¨æˆ·æ„å›¾ã€‚"},
                    {"role": "user", "content": analysis_prompt}
                ],
                temperature=0.1,
                max_tokens=500,
                extra_body={"enable_thinking": False}
            )

            content = response.choices[0].message.content

            # è§£æLLMå“åº”
            try:
                # å°è¯•ç›´æ¥è§£æJSON
                analysis_data = json.loads(content)
            except json.JSONDecodeError:
                # æå–JSONä»£ç å—
                import re
                json_match = re.search(r'```json\s*(.*?)\s*```', content, re.DOTALL)
                if json_match:
                    analysis_data = json.loads(json_match.group(1))
                else:
                    # é™çº§åˆ°ç®€å•åˆ†æ
                    analysis_data = self._simple_query_analysis(question)

            return QueryAnalysis(
                entities=analysis_data.get("entities", []),
                intent_type=analysis_data.get("intent_type", "factual"),
                complexity=analysis_data.get("complexity", "medium"),
                requires_llm=analysis_data.get("requires_llm", False)
            )

        except Exception as e:
            self.logger.warning(f"LLMæŸ¥è¯¢åˆ†æå¤±è´¥: {e}ï¼Œä½¿ç”¨ç®€å•åˆ†æ")
            return self._simple_query_analysis(question)

    def _simple_query_analysis(self, question: str) -> QueryAnalysis:
        """ç®€å•æŸ¥è¯¢åˆ†æï¼ˆé™çº§æ–¹æ¡ˆï¼‰"""
        # æå–å…³é”®è¯ä½œä¸ºå®ä½“
        import re
        words = re.findall(r'[\u4e00-\u9fff]+|[a-zA-Z]+', question)
        entities = [w for w in words if len(w) > 1]

        # ç®€å•å¯å‘å¼åˆ¤æ–­
        question_lower = question.lower()
        if any(word in question_lower for word in ['ä»€ä¹ˆ', 'ä»€ä¹ˆæ˜¯', 'what is']):
            intent_type = "factual"
        elif any(word in question_lower for word in ['ä¸ºä»€ä¹ˆ', 'why', 'å¦‚ä½•', 'how']):
            intent_type = "causal"
        elif any(word in question_lower for word in ['æ¯”è¾ƒ', 'å¯¹æ¯”', 'compare']):
            intent_type = "comparative"
        else:
            intent_type = "procedural"

        complexity = "simple" if len(entities) <= 2 else "complex"
        requires_llm = complexity == "complex" or intent_type in ["causal", "comparative"]

        return QueryAnalysis(
            entities=entities,
            intent_type=intent_type,
            complexity=complexity,
            requires_llm=requires_llm
        )

    async def _graph_based_reasoning(self, question: str, query_analysis: QueryAnalysis) -> List[ReasoningResult]:
        """åŸºäºå›¾ç®—æ³•çš„æ¨ç†"""
        try:
            # ä½¿ç”¨å›¾æ¨ç†å¼•æ“
            results = self.graph_reasoner.query(question, max_results=5)
            return results
        except Exception as e:
            self.logger.error(f"å›¾æ¨ç†å¤±è´¥: {e}")
            return []

    async def _llm_based_reasoning(self, question: str, relevant_triples: List[Triple]) -> Dict[str, Any]:
        """åŸºäºLLMçš„è¯­ä¹‰æ¨ç†"""
        if not relevant_triples:
            return {
                "answer": "æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯æ¥å›ç­”æ‚¨çš„é—®é¢˜ã€‚",
                "confidence": 0.0,
                "insights": []
            }

        try:
            # å‡†å¤‡ä¸‰å…ƒç»„ä¸Šä¸‹æ–‡
            triples_text = "\n".join([
                f"- {triple.subject} -> {triple.predicate} -> {triple.object}"
                for triple in relevant_triples[:10]  # é™åˆ¶æ•°é‡
            ])

            reasoning_prompt = f"""
åŸºäºä»¥ä¸‹çŸ¥è¯†å›¾è°±ä¸‰å…ƒç»„ï¼Œè¯·å›ç­”ç”¨æˆ·é—®é¢˜ï¼š

çŸ¥è¯†å›¾è°±ä¿¡æ¯ï¼š
{triples_text}

ç”¨æˆ·é—®é¢˜ï¼š{question}

è¯·æä¾›ï¼š
1. åŸºäºå·²çŸ¥ä¿¡æ¯çš„ç›´æ¥å›ç­”
2. è¯­ä¹‰æ¨ç†å’Œå¸¸è¯†è¡¥å……
3. å›ç­”çš„ç½®ä¿¡åº¦è¯„ä¼°

è¯·è¿”å›JSONæ ¼å¼ï¼š
{{
    "answer": "è¯¦ç»†å›ç­”",
    "confidence": 0.8,
    "insights": ["æ¨ç†æ´å¯Ÿ1", "æ¨ç†æ´å¯Ÿ2"],
    "reasoning": "æ¨ç†è¿‡ç¨‹è¯´æ˜"
}}
"""

            response = await self.llm_client.chat.completions.create(
                model=self.config.openai.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†æ¨ç†ä¸“å®¶ï¼Œæ“…é•¿åŸºäºç»“æ„åŒ–çŸ¥è¯†è¿›è¡Œè¯­ä¹‰æ¨ç†ã€‚"},
                    {"role": "user", "content": reasoning_prompt}
                ],
                temperature=0.3,
                max_tokens=1000,
                extra_body={"enable_thinking": False}
            )

            content = response.choices[0].message.content

            # è§£æå“åº”
            try:
                import re
                json_match = re.search(r'```json\s*(.*?)\s*```', content, re.DOTALL)
                if json_match:
                    result = json.loads(json_match.group(1))
                else:
                    result = json.loads(content)
            except json.JSONDecodeError:
                result = {
                    "answer": content,
                    "confidence": 0.5,
                    "insights": ["LLMæ¨ç†å®Œæˆ"],
                    "reasoning": "åŸºäºè¯­ä¹‰ç†è§£çš„æ¨ç†"
                }

            return result

        except Exception as e:
            self.logger.error(f"LLMæ¨ç†å¤±è´¥: {e}")
            return {
                "answer": f"æ¨ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}",
                "confidence": 0.0,
                "insights": [],
                "reasoning": "æ¨ç†å¤±è´¥"
            }

    async def _path_enhanced_reasoning(self, entities: List[str]) -> List[PathResult]:
        """è·¯å¾„å¢å¼ºæ¨ç†"""
        paths = []

        if len(entities) >= 2:
            # æŸ¥æ‰¾å®ä½“é—´çš„è·¯å¾„
            for i in range(len(entities)):
                for j in range(i + 1, min(i + 3, len(entities))):  # é™åˆ¶æ¯”è¾ƒæ•°é‡
                    path = self.graph_reasoner.find_shortest_path(entities[i], entities[j])
                    if path and path.length <= 4:  # é™åˆ¶è·¯å¾„é•¿åº¦
                        paths.append(path)

        return paths

    async def _synthesize_results(
        self,
        question: str,
        graph_results: List[ReasoningResult],
        llm_result: Dict[str, Any],
        paths: List[PathResult],
        query_analysis: QueryAnalysis
    ) -> HybridReasoningResult:
        """ç»¼åˆå¤šç§æ¨ç†ç»“æœ"""

        # åŸºç¡€ç½®ä¿¡åº¦è®¡ç®—
        graph_confidence = max([r.confidence for r in graph_results], default=0.0)
        llm_confidence = llm_result.get("confidence", 0.0)

        # æ ¹æ®æŸ¥è¯¢ç±»å‹è°ƒæ•´æƒé‡
        if query_analysis.intent_type == "factual":
            final_confidence = graph_confidence * 0.7 + llm_confidence * 0.3
        elif query_analysis.intent_type in ["causal", "comparative"]:
            final_confidence = graph_confidence * 0.4 + llm_confidence * 0.6
        else:
            final_confidence = graph_confidence * 0.5 + llm_confidence * 0.5

        # æ„å»ºå›ç­”
        if graph_results and llm_result.get("confidence", 0) > 0.5:
            # æ··åˆå›ç­”
            primary_answer = graph_results[0].answer if graph_results else ""
            llm_enhancement = llm_result.get("answer", "")

            if primary_answer and llm_enhancement and primary_answer != llm_enhancement:
                answer = f"{primary_answer}\n\nğŸ’¡ æ·±åº¦åˆ†æï¼š{llm_enhancement}"
            else:
                answer = primary_answer or llm_enhancement
        elif graph_results:
            answer = graph_results[0].answer
        else:
            answer = llm_result.get("answer", "æŠ±æ­‰ï¼Œæ— æ³•å›ç­”æ‚¨çš„é—®é¢˜ã€‚")

        # æå–æ”¯æŒä¿¡æ¯
        supporting_triples = []
        for result in graph_results:
            supporting_triples.extend(result.supporting_triples)

        # æ„å»ºè·¯å¾„ä¿¡æ¯
        graph_paths = []
        for path in paths:
            graph_paths.append(" â†’ ".join(path.path))

        # æå–è¯­ä¹‰æ´å¯Ÿ
        semantic_insights = llm_result.get("insights", [])

        # ç¡®å®šæ¨ç†æ–¹æ³•
        if graph_results and llm_result.get("confidence", 0) > 0.5:
            reasoning_method = "æ··åˆæ¨ç†ï¼ˆå›¾ç®—æ³• + LLMè¯­ä¹‰ç†è§£ï¼‰"
        elif graph_results:
            reasoning_method = "å›¾ç®—æ³•æ¨ç†"
        else:
            reasoning_method = "LLMè¯­ä¹‰æ¨ç†"

        return HybridReasoningResult(
            answer=answer,
            confidence=min(1.0, final_confidence),
            reasoning_method=reasoning_method,
            graph_paths=graph_paths,
            semantic_insights=semantic_insights,
            supporting_triples=supporting_triples[:10],  # é™åˆ¶æ•°é‡
            llm_enhancement=llm_result.get("answer") if llm_result.get("confidence", 0) > 0.5 else None,
            processing_time=0.0  # å®é™…ä½¿ç”¨æ—¶éœ€è¦è®¡ç®—
        )

    async def query(self, question: str, knowledge_graph: KnowledgeGraph) -> HybridReasoningResult:
        """æ··åˆæ¨ç†æŸ¥è¯¢"""
        import time
        start_time = time.time()

        try:
            self.logger.info(f"å¼€å§‹æ··åˆæ¨ç†æŸ¥è¯¢: {question}")

            # æ›´æ–°çŸ¥è¯†å›¾è°±
            self.update_knowledge_graph(knowledge_graph)

            # 1. åˆ†ææŸ¥è¯¢
            query_analysis = await self._analyze_query(question)
            self.logger.info(f"æŸ¥è¯¢åˆ†æ: {query_analysis.intent_type}, {query_analysis.complexity}")

            # 2. å›¾ç®—æ³•æ¨ç†
            graph_results = await self._graph_based_reasoning(question, query_analysis)
            self.logger.info(f"å›¾æ¨ç†ç»“æœ: {len(graph_results)} ä¸ª")

            # 3. è·¯å¾„å¢å¼ºæ¨ç†
            paths = []
            if query_analysis.entities and len(query_analysis.entities) >= 2:
                paths = await self._path_enhanced_reasoning(query_analysis.entities)
                self.logger.info(f"è·¯å¾„æ¨ç†: {len(paths)} æ¡è·¯å¾„")

            # 4. LLMè¯­ä¹‰æ¨ç†ï¼ˆå¦‚æœéœ€è¦ï¼‰
            llm_result = {}
            if query_analysis.requires_llm or not graph_results:
                relevant_triples = []
                for result in graph_results:
                    relevant_triples.extend(result.supporting_triples)

                llm_result = await self._llm_based_reasoning(question, relevant_triples)
                self.logger.info(f"LLMæ¨ç†å®Œæˆï¼Œç½®ä¿¡åº¦: {llm_result.get('confidence', 0):.2f}")

            # 5. ç»¼åˆç»“æœ
            final_result = await self._synthesize_results(
                question, graph_results, llm_result, paths, query_analysis
            )

            final_result.processing_time = time.time() - start_time
            self.logger.info(f"æ··åˆæ¨ç†å®Œæˆï¼Œç½®ä¿¡åº¦: {final_result.confidence:.2f}")

            return final_result

        except Exception as e:
            self.logger.error(f"æ··åˆæ¨ç†å¤±è´¥: {e}")
            return HybridReasoningResult(
                answer=f"æ¨ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}",
                confidence=0.0,
                reasoning_method="é”™è¯¯",
                graph_paths=[],
                semantic_insights=[],
                supporting_triples=[],
                llm_enhancement=None,
                processing_time=time.time() - start_time
            )

    # åŒæ­¥æ–¹æ³•ï¼ˆå‘åå…¼å®¹ï¼‰
    def query_sync(self, question: str, knowledge_graph: KnowledgeGraph) -> HybridReasoningResult:
        """åŒæ­¥ç‰ˆæœ¬çš„æŸ¥è¯¢æ–¹æ³•"""
        import asyncio
        return asyncio.run(self.query(question, knowledge_graph))